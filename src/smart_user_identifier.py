#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import re
from collections import Counter, defaultdict
from typing import List, Dict, Tuple
import os
from user_directory_manager import user_directory_manager

def extract_message_samples(file_path: str, sample_count: int) -> List[Tuple[str, str, str]]:
    """
    å¾èŠå¤©è¨˜éŒ„ä¸­æå–å‰Nçµ„å°è©±çš„æ¨£æœ¬
    
    Args:
        file_path: èŠå¤©è¨˜éŒ„æª”æ¡ˆè·¯å¾‘
        sample_count: è¦æå–çš„æ¨£æœ¬æ•¸é‡
        
    Returns:
        è¨Šæ¯æ¨£æœ¬åˆ—è¡¨ [(æ™‚é–“, ä½¿ç”¨è€…, å…§å®¹), ...]
    """
    samples = []
    current_date = None
    
    # æ”¯æ´å¤šç¨®æ—¥æœŸæ ¼å¼
    date_patterns = [
        re.compile(r"^(\d{4})\.(\d{2})\.(\d{2})\s+æ˜ŸæœŸ."),
        re.compile(r"^(\d{4})/(\d{1,2})/(\d{1,2})ï¼ˆé€±."),
    ]
    
    # ä½¿ç”¨èˆ‡ chat_parser.py ç›¸åŒçš„æ­£å‰‡è¡¨é”å¼æ¨¡å¼
    tab_message_pattern = re.compile(r"^(\d{2}:\d{2})\t(.+?)\t(.+)")
    time_pattern = re.compile(r"^(\d{2}:\d{2})\s+(.+)")
    
    with open(file_path, "r", encoding="utf-8") as f:
        for line in f:
            if len(samples) >= sample_count:
                break
                
            line = line.strip()
            if not line or line.startswith("[LINE]") or line.startswith("å„²å­˜æ—¥æœŸï¼š"):
                continue
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºæ—¥æœŸè¡Œ
            date_match = None
            for pattern in date_patterns:
                date_match = pattern.match(line)
                if date_match:
                    break
            
            if date_match:
                y, m, d = date_match.groups()
                current_date = f"{int(y):04d}-{int(m):02d}-{int(d):02d}"
                continue
            
            if current_date is None:
                continue
            
            # è™•ç†è¨Šæ¯è¡Œ - ä½¿ç”¨èˆ‡ chat_parser.py ç›¸åŒçš„é‚è¼¯
            user = None
            content = None
            time = None
            
            # å…ˆå˜—è©¦ tab åˆ†éš”æ ¼å¼
            msg_match = tab_message_pattern.match(line)
            if msg_match:
                time, user, content = msg_match.groups()
            else:
                # ä½¿ç”¨ç©ºæ ¼åˆ†éš”æ ¼å¼ï¼Œéœ€è¦æ™ºèƒ½è§£æ
                time_match = time_pattern.match(line)
                if time_match:
                    time, remaining = time_match.groups()
                    # æ™ºèƒ½è§£æï¼šå˜—è©¦è­˜åˆ¥å®Œæ•´çš„ä½¿ç”¨è€…åç¨±
                    parts = remaining.split()
                    
                    if len(parts) >= 1:
                        # ä½¿ç”¨èˆ‡ chat_parser.py ç›¸åŒçš„ extract_user_and_content é‚è¼¯
                        user, content = extract_user_and_content_simple(parts)
                    else:
                        user = ""
                        content = ""
            
            if user and content and time:
                samples.append((time, user, content))
    
    return samples

def extract_user_and_content_simple(parts: List[str]) -> Tuple[str, str]:
    """
    ç°¡åŒ–ç‰ˆçš„ä½¿ç”¨è€…åç¨±å’Œå…§å®¹è§£æï¼ˆç”¨æ–¼æ¨£æœ¬æå–ï¼‰
    
    Args:
        parts: åˆ†å‰²å¾Œçš„æ–‡å­—éƒ¨åˆ†åˆ—è¡¨
        
    Returns:
        (user, content): ä½¿ç”¨è€…åç¨±å’Œå…§å®¹çš„å…ƒçµ„
    """
    if not parts:
        return "", ""
    
    # å¦‚æœåªæœ‰ä¸€å€‹éƒ¨åˆ†ï¼Œç›´æ¥è¿”å›
    if len(parts) == 1:
        return parts[0], ""
    
    # æ–¹æ³•0ï¼šå„ªå…ˆè™•ç†ç°¡çŸ­æ˜ç¢ºçš„ä½¿ç”¨è€…åç¨±ï¼ˆå¦‚ "WhoAmI"ï¼‰
    # æª¢æŸ¥ç¬¬ä¸€å€‹éƒ¨åˆ†æ˜¯å¦ç‚ºæ˜ç¢ºçš„ä½¿ç”¨è€…åç¨±
    first_part = parts[0]
    
    # ç°¡çŸ­æ˜ç¢ºçš„ä½¿ç”¨è€…åç¨±ç‰¹å¾µï¼š
    # 1. é•·åº¦é©ä¸­ï¼ˆå¯é…ç½®ç¯„åœï¼‰
    # 2. ä¸åŒ…å«ç©ºæ ¼
    # 3. ä¸æ˜¯è¡¨æƒ…ç¬¦è™Ÿæˆ–ç‰¹æ®Šç¬¦è™Ÿ
    # 4. ä¸æ˜¯URL
    # 5. ä¸æ˜¯æ˜é¡¯çš„å…§å®¹è©
    min_username_length = 2
    max_username_length = 15
    
    # å¾é…ç½®ä¸­ç²å–ä½¿ç”¨è€…åç¨±é•·åº¦é™åˆ¶
    try:
        import json
        with open('config.json', 'r', encoding='utf-8') as f:
            config = json.load(f)
        min_username_length = config['analysis_settings']['min_user_name_length_ç”¨æˆ¶åæœ€å°é•·åº¦']
        max_username_length = config['analysis_settings']['max_user_name_length_ç”¨æˆ¶åæœ€å¤§é•·åº¦']
    except:
        pass  # å¦‚æœç„¡æ³•è®€å–é…ç½®ï¼Œä½¿ç”¨é»˜èªå€¼
    
    # å¾é…ç½®ä¸­ç²å–è§£æè¨­ç½®
    emoji_chars = ['ğŸ˜€', 'ğŸ˜‚', 'ğŸ˜…', 'ğŸ™', 'ï½']  # é»˜èªå€¼
    content_indicators = ['è²¼åœ–', 'åœ–ç‰‡', 'å½±ç‰‡', 'èªéŸ³è¨Šæ¯', 'æª”æ¡ˆ', 'ä½ç½®']  # é»˜èªå€¼
    conversation_starters = ['å—¨å—¨', 'æƒ³è·Ÿä½ è¨æ•™', 'é †ä¾¿å•ä¸€ä¸‹', 'æˆ‘é‚„æ˜¯å…ˆ', 'æˆ‘æŠŠæ¨“ä¸Š', 'åˆç´„éƒ½', 'ç„¶å¾Œ', 'Userï½']  # é»˜èªå€¼
    
    try:
        import json
        with open('config.json', 'r', encoding='utf-8') as f:
            config = json.load(f)
        parsing_settings = config.get('parsing_settings', {})
        emoji_chars = parsing_settings.get('emoji_chars', emoji_chars)
        content_indicators = parsing_settings.get('content_indicators', content_indicators)
        conversation_starters = parsing_settings.get('conversation_starters', conversation_starters)
    except:
        pass  # å¦‚æœç„¡æ³•è®€å–é…ç½®ï¼Œä½¿ç”¨é»˜èªå€¼
    
    if (min_username_length <= len(first_part) <= max_username_length and 
        ' ' not in first_part and 
        not any(char in first_part for char in emoji_chars) and
        not first_part.startswith('http') and
        first_part not in content_indicators and
        first_part not in conversation_starters):
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºå·²çŸ¥ä½¿ç”¨è€…
        result = user_directory_manager.find_user_by_name(first_part)
        if result:
            content = ' '.join(parts[1:]) if len(parts) > 1 else ""
            return result, content
        
        # å¦‚æœç¬¬ä¸€å€‹éƒ¨åˆ†çœ‹èµ·ä¾†åƒä½¿ç”¨è€…åç¨±ï¼Œç›´æ¥ä½¿ç”¨
        content = ' '.join(parts[1:]) if len(parts) > 1 else ""
        return first_part, content
    
    # æ–¹æ³•1ï¼šä½¿ç”¨ä½¿ç”¨è€…åå†Šï¼ˆå®Œå…¨æ¯”å°ï¼‰
    for i in range(1, min(len(parts) + 1, 6)):
        potential_user = ' '.join(parts[:i])
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºå·²çŸ¥ä½¿ç”¨è€…ï¼ˆå®Œå…¨æ¯”å°ï¼‰
        result = user_directory_manager.find_user_by_name(potential_user)
        if result:
            content = ' '.join(parts[i:]) if i < len(parts) else ""
            return result, content
    
    # æ–¹æ³•1ï¼šæª¢æŸ¥æ˜¯å¦æœ‰æ˜é¡¯çš„å…§å®¹æ¨™è¨˜
    content_indicators = ['è²¼åœ–', 'åœ–ç‰‡', 'å½±ç‰‡', 'èªéŸ³è¨Šæ¯', 'æª”æ¡ˆ', 'ä½ç½®']
    
    for i in range(1, min(len(parts) + 1, 6)):
        potential_user = ' '.join(parts[:i])
        remaining_parts = parts[i:]
        
        if remaining_parts:
            first_remaining = remaining_parts[0]
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºå…§å®¹æ¨™è¨˜
            if first_remaining in content_indicators:
                content = ' '.join(remaining_parts)
                return potential_user, content
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºè¡¨æƒ…ç¬¦è™Ÿæˆ–ç‰¹æ®Šç¬¦è™Ÿ
            if any(char in first_remaining for char in ['ğŸ˜€', 'ğŸ˜‚', 'ğŸ˜…', 'ğŸ™', 'ï½', 'ï½', 'ï½']):
                content = ' '.join(remaining_parts)
                return potential_user, content
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºURL
            if first_remaining.startswith('http'):
                content = ' '.join(remaining_parts)
                return potential_user, content
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºå¸¸è¦‹çš„å°è©±å…§å®¹é–‹é ­
            if first_remaining in ['å—¨å—¨', 'æƒ³è·Ÿä½ è¨æ•™', 'é †ä¾¿å•ä¸€ä¸‹', 'æˆ‘é‚„æ˜¯å…ˆ', 'æˆ‘æŠŠæ¨“ä¸Š', 'åˆç´„éƒ½', 'ç„¶å¾Œ', 'Userï½']:
                content = ' '.join(remaining_parts)
                return potential_user, content
    
    # æ–¹æ³•2ï¼šæª¢æŸ¥æ˜¯å¦ç‚ºå¤šéƒ¨åˆ†ä½¿ç”¨è€…åç¨±ï¼ˆåŒ…å«ä¸‹åŠƒç·šå’Œç©ºæ ¼ï¼‰
    for i in range(2, min(len(parts) + 1, 6)):  # å¾2å€‹éƒ¨åˆ†é–‹å§‹æª¢æŸ¥
        potential_user = ' '.join(parts[:i])
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«ä¸‹åŠƒç·šä¸”é•·åº¦è¼ƒé•·ï¼ˆå¯èƒ½æ˜¯å®Œæ•´çš„ä½¿ç”¨è€…åç¨±ï¼‰
        if '_' in potential_user and len(potential_user) > 10:
            content = ' '.join(parts[i:]) if i < len(parts) else ""
            return potential_user, content
    
    # æ–¹æ³•3ï¼šåŸºæ–¼ä½¿ç”¨è€…åç¨±çš„å¸¸è¦‹æ¨¡å¼ (ä¸‹åŠƒç·š)
    for i in range(1, min(len(parts) + 1, 6)):
        potential_user = ' '.join(parts[:i])
        if '_' in potential_user:
            content = ' '.join(parts[i:]) if i < len(parts) else ""
            return potential_user, content
    
    # æ–¹æ³•4ï¼šæª¢æŸ¥ä¸­æ–‡+è‹±æ–‡æ¨¡å¼
    for i in range(1, min(len(parts) + 1, 6)):
        potential_user = ' '.join(parts[:i])
        has_chinese = any('\u4e00' <= char <= '\u9fff' for char in potential_user)
        has_english = any(char.isalpha() and ord(char) < 128 for char in potential_user)
        if has_chinese and has_english:
            content = ' '.join(parts[i:]) if i < len(parts) else ""
            return potential_user, content
    
    # æ–¹æ³•5ï¼šæª¢æŸ¥æ˜¯å¦ç‚ºå¸¸è¦‹çš„å…§å®¹é–‹é ­è©
    content_start_words = ['youtote', 'Momo', 'My', 'From', 'One', 'ã€', 'Lalamove', 'ä¸‹è¼‰ä½ç½®']
    for i in range(1, min(len(parts) + 1, 6)):
        potential_user = ' '.join(parts[:i])
        remaining_parts = parts[i:]
        if remaining_parts:
            first_remaining = remaining_parts[0]
            if first_remaining in content_start_words:
                content = ' '.join(remaining_parts)
                return potential_user, content
    
    # æœ€çµ‚å›é€€ï¼šä½¿ç”¨ç¬¬ä¸€å€‹éƒ¨åˆ†ä½œç‚ºä½¿ç”¨è€…åç¨±
    user = parts[0]
    content = ' '.join(parts[1:]) if len(parts) > 1 else ""
    return user, content

def analyze_user_patterns(samples: List[Tuple[str, str, str]]) -> Dict[str, Dict]:
    """
    åˆ†æä½¿ç”¨è€…åç¨±æ¨¡å¼ï¼Œæ‰¾å‡ºé‡è¤‡å‡ºç¾çš„ä½¿ç”¨è€…å­—ä¸²
    
    Args:
        samples: è¨Šæ¯æ¨£æœ¬åˆ—è¡¨
        
    Returns:
        ä½¿ç”¨è€…åˆ†æçµæœå­—å…¸
    """
    if not samples:
        return {}
    
    # çµ±è¨ˆä½¿ç”¨è€…å‡ºç¾æ¬¡æ•¸
    user_counter = Counter()
    user_content_patterns = defaultdict(list)
    
    for time, user, content in samples:
        user_counter[user] += 1
        # å¾é…ç½®ä¸­ç²å–å…§å®¹æˆªå–é•·åº¦ï¼Œå¦‚æœæ²’æœ‰é…ç½®å‰‡ä½¿ç”¨é»˜èªå€¼
        content_length_limit = 50  # é»˜èªå€¼
        try:
            import json
            with open('config.json', 'r', encoding='utf-8') as f:
                config = json.load(f)
            # ä½¿ç”¨ç”¨æˆ¶åæœ€å¤§é•·åº¦ä½œç‚ºå…§å®¹æˆªå–é•·åº¦çš„åƒè€ƒ
            content_length_limit = config['analysis_settings']['max_user_name_length_ç”¨æˆ¶åæœ€å¤§é•·åº¦']
        except:
            pass  # å¦‚æœç„¡æ³•è®€å–é…ç½®ï¼Œä½¿ç”¨é»˜èªå€¼
        
        user_content_patterns[user].append(content[:content_length_limit])  # åªå–å‰Nå€‹å­—ç¬¦
    
    # åˆ†æçµæœ
    analysis = {}
    
    for user, count in user_counter.most_common():
        # è¨ˆç®—è©²ä½¿ç”¨è€…çš„å…§å®¹å¤šæ¨£æ€§
        content_samples = user_content_patterns[user]
        unique_contents = len(set(content_samples))
        content_diversity = unique_contents / len(content_samples) if content_samples else 0
        
        # æª¢æŸ¥ä½¿ç”¨è€…åç¨±æ˜¯å¦åŒ…å«ç‰¹æ®Šå­—ç¬¦æˆ–æ¨¡å¼
        has_underscore = '_' in user
        has_chinese = any('\u4e00' <= char <= '\u9fff' for char in user)
        has_english = any(char.isalpha() and ord(char) < 128 for char in user)
        has_numbers = any(char.isdigit() for char in user)
        
        analysis[user] = {
            'count': count,
            'frequency': count / len(samples),
            'content_diversity': content_diversity,
            'has_underscore': has_underscore,
            'has_chinese': has_chinese,
            'has_english': has_english,
            'has_numbers': has_numbers,
            'length': len(user),
            'content_samples': content_samples[:5]  # åªä¿ç•™å‰5å€‹æ¨£æœ¬
        }
    
    return analysis

def identify_real_users(analysis: Dict[str, Dict], min_frequency: float, config: Dict) -> List[str]:
    """
    æ ¹æ“šåˆ†æçµæœè­˜åˆ¥çœŸæ­£çš„ä½¿ç”¨è€…åç¨±ï¼ˆç¤¾ç¾¤ç’°å¢ƒå„ªåŒ–ï¼‰
    
    Args:
        analysis: ä½¿ç”¨è€…åˆ†æçµæœ
        min_frequency: æœ€å°å‡ºç¾é »ç‡é–¾å€¼
        config: é…ç½®å­—å…¸ï¼ŒåŒ…å«åˆ†æè¨­å®š
        
    Returns:
        è­˜åˆ¥å‡ºçš„çœŸæ­£ä½¿ç”¨è€…åç¨±åˆ—è¡¨
    """
    real_users = []
    
    for user, stats in analysis.items():
        # æ’é™¤æ˜é¡¯çš„ç³»çµ±è¨Šæ¯
        if user.lower() in ['system', 'admin']:
            continue
        
        # æ’é™¤ç³»çµ±è¨Šæ¯ï¼ˆä½†ä¿ç•™ "Unknown"ï¼Œå› ç‚ºå®ƒå¯èƒ½æ˜¯çœŸæ­£çš„ä½¿ç”¨è€…ï¼‰
        if 'åŠ å…¥èŠå¤©' in user or user in ['å’»å’»å’»', 'é»', 'ç‘ªèˆç·¹é›…', 'åµ', 'Bruce']:
            continue
        
        # æ’é™¤æ˜é¡¯çš„æ©Ÿå™¨äººæˆ–å»£å‘Šå¸³è™Ÿ
        if any(keyword in user.lower() for keyword in ['bot', 'å»£å‘Š', 'spam', 'auto']):
            continue
        
        # å¾é…ç½®ä¸­ç²å–åƒæ•¸
        min_length = config['analysis_settings']['min_user_name_length_ç”¨æˆ¶åæœ€å°é•·åº¦']
        max_length = config['analysis_settings']['max_user_name_length_ç”¨æˆ¶åæœ€å¤§é•·åº¦']
        min_diversity = config['analysis_settings']['min_content_diversity_æœ€å°å…§å®¹å¤šæ¨£æ€§']
        
        # æ’é™¤éçŸ­æˆ–éé•·çš„åç¨±
        if stats['length'] < min_length or stats['length'] > max_length:
            continue
        
        # æª¢æŸ¥å‡ºç¾é »ç‡ï¼ˆç¤¾ç¾¤ç’°å¢ƒä¸­é™ä½é–¾å€¼ï¼‰
        if stats['frequency'] < min_frequency:
            continue
        
        # æª¢æŸ¥å…§å®¹å¤šæ¨£æ€§ï¼ˆç¤¾ç¾¤ç’°å¢ƒä¸­é™ä½è¦æ±‚ï¼‰
        if stats['content_diversity'] < min_diversity:
            continue
        
        # ç¤¾ç¾¤ç’°å¢ƒç‰¹æ®Šæª¢æŸ¥ï¼šæª¢æŸ¥æ˜¯å¦ç‚ºæœ‰æ„ç¾©çš„ä½¿ç”¨è€…åç¨±
        # æ’é™¤ç´”æ•¸å­—ã€ç´”ç¬¦è™Ÿç­‰
        if user.isdigit() or all(not char.isalnum() for char in user):
            continue
        
        # å¦‚æœé€šéæ‰€æœ‰æª¢æŸ¥ï¼Œèªç‚ºæ˜¯çœŸæ­£ä½¿ç”¨è€…
        real_users.append(user)
    
    # éæ¿¾è®Šé«”ï¼šç§»é™¤æ˜é¡¯æ˜¯è®Šé«”çš„ä½¿ç”¨è€…åç¨±
    filtered_users = []
    for user in real_users:
        is_variant = False
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºå…¶ä»–ä½¿ç”¨è€…çš„è®Šé«”
        for other_user in real_users:
            if user != other_user:
                # æª¢æŸ¥æ˜¯å¦ç‚ºåŒ…å«é—œä¿‚ï¼ˆè®Šé«”é€šå¸¸åŒ…å«æ¨™æº–åç¨±ï¼‰
                if other_user in user and len(user) > len(other_user) + 5:
                    # å¦‚æœä¸€å€‹åç¨±åŒ…å«å¦ä¸€å€‹åç¨±ï¼Œä¸”é•·åº¦å·®ç•°è¼ƒå¤§ï¼Œå¯èƒ½æ˜¯è®Šé«”
                    is_variant = True
                    break
                
                # æª¢æŸ¥æ˜¯å¦æœ‰å…±åŒå‰ç¶´ä¸”é•·åº¦å·®ç•°è¼ƒå¤§
                if user.startswith(other_user) and len(user) > len(other_user) + 3:
                    is_variant = True
                    break
        
        if not is_variant:
            filtered_users.append(user)
    
    # æŒ‰å‡ºç¾é »ç‡æ’åº
    filtered_users.sort(key=lambda u: analysis[u]['count'], reverse=True)
    
    return filtered_users

def create_user_mapping(real_users: List[str], analysis: Dict[str, Dict]) -> Dict[str, str]:
    """
    å‰µå»ºä½¿ç”¨è€…åç¨±æ˜ å°„ï¼Œå°‡è®Šé«”æ˜ å°„åˆ°æ¨™æº–åç¨±
    
    Args:
        real_users: è­˜åˆ¥å‡ºçš„çœŸæ­£ä½¿ç”¨è€…åç¨±åˆ—è¡¨
        analysis: ä½¿ç”¨è€…åˆ†æçµæœ
        
    Returns:
        ä½¿ç”¨è€…åç¨±æ˜ å°„å­—å…¸
    """
    mapping = {}
    
    # æŒ‰é »ç‡æ’åºï¼Œé »ç‡é«˜çš„ä½œç‚ºæ¨™æº–åç¨±
    sorted_users = sorted(real_users, key=lambda x: analysis[x]['count'], reverse=True)
    
    # å°æ–¼æ¯å€‹è­˜åˆ¥å‡ºçš„çœŸæ­£ä½¿ç”¨è€…ï¼Œå‰µå»ºæ¨™æº–åŒ–æ˜ å°„
    for user in analysis.keys():
        if user not in real_users:
            # æ‰¾åˆ°æœ€åŒ¹é…çš„æ¨™æº–ä½¿ç”¨è€…åç¨±
            best_match = None
            best_score = 0
            
            for real_user in sorted_users:
                score = 0
                
                # æª¢æŸ¥æ˜¯å¦ç‚ºåŒ…å«é—œä¿‚
                if real_user in user:
                    score += 10
                elif user in real_user:
                    score += 5
                
                # æª¢æŸ¥ä¸‹åŠƒç·šå‰çš„éƒ¨åˆ†æ˜¯å¦ç›¸åŒ
                if '_' in real_user and '_' in user:
                    if real_user.split('_')[0] == user.split('_')[0]:
                        score += 8
                
                # æª¢æŸ¥æ˜¯å¦æœ‰å…±åŒçš„å‰ç¶´
                common_prefix = ""
                for i, (c1, c2) in enumerate(zip(real_user, user)):
                    if c1 == c2:
                        common_prefix += c1
                    else:
                        break
                
                if len(common_prefix) > 3:  # è‡³å°‘3å€‹å­—ç¬¦çš„å…±åŒå‰ç¶´
                    score += len(common_prefix)
                
                if score > best_score:
                    best_score = score
                    best_match = real_user
            
            # å¦‚æœæ‰¾åˆ°åˆé©çš„åŒ¹é…ï¼Œå‰µå»ºæ˜ å°„
            if best_match and best_score >= 5:  # æœ€ä½åŒ¹é…åˆ†æ•¸
                mapping[user] = best_match
    
    # ç‰¹æ®Šè™•ç†ï¼šç‚º "Unknown" ä½¿ç”¨è€…æä¾›æ›´æœ‰æ„ç¾©çš„æ¨™è­˜
    if 'Unknown' in real_users:
        # å¯ä»¥æ ¹æ“šå…§å®¹ç‰¹å¾µç‚º Unknown ä½¿ç”¨è€…åˆ†é…ä¸€å€‹æ›´æœ‰æ„ç¾©çš„åç¨±
        # ä¾‹å¦‚ï¼šæ ¹æ“šå°è©±å…§å®¹çš„ç‰¹å¾µä¾†æ¨æ¸¬å¯èƒ½çš„èº«ä»½
        unknown_stats = analysis.get('Unknown', {})
        if unknown_stats.get('count', 0) > 10:  # å¦‚æœ Unknown å‡ºç¾å¾ˆå¤šæ¬¡
            # å¯ä»¥è€ƒæ…®å°‡å…¶æ˜ å°„ç‚º "é›¢ç¾¤ä½¿ç”¨è€…" æˆ– "åŒ¿åä½¿ç”¨è€…"
            # é€™è£¡æš«æ™‚ä¿æŒ "Unknown"ï¼Œä½†å¯ä»¥æ ¹æ“šéœ€è¦è‡ªå®šç¾©
            pass
    
    return mapping

def detect_chat_format(samples: List[Tuple[str, str, str]]) -> str:
    """
    æª¢æ¸¬èŠå¤©è¨˜éŒ„çš„æ ¼å¼é¡å‹
    
    Args:
        samples: è¨Šæ¯æ¨£æœ¬åˆ—è¡¨
        
    Returns:
        æ ¼å¼é¡å‹ï¼š'group'ï¼ˆç¤¾ç¾¤ï¼‰æˆ– 'private'ï¼ˆç§èŠï¼‰
    """
    if not samples:
        return 'private'
    
    # çµ±è¨ˆä¸åŒä½¿ç”¨è€…æ•¸é‡
    unique_users = len(set(user for _, user, _ in samples))
    
    # æª¢æŸ¥æ˜¯å¦æœ‰ç³»çµ±è¨Šæ¯ç‰¹å¾µ
    system_keywords = ['åŠ å…¥èŠå¤©', 'é€€å‡ºç¾¤çµ„', 'é€€å‡ºç¤¾ç¾¤', 'å°é–', 'è§£é™¤å°é–']
    has_system_msgs = any(any(keyword in content for keyword in system_keywords) 
                         for _, _, content in samples)
    
    # æª¢æŸ¥ä½¿ç”¨è€…åç¨±ç‰¹å¾µ
    user_names = [user for _, user, _ in samples]
    has_complex_names = any('_' in user or len(user.split()) > 1 for user in user_names)
    
    # æª¢æŸ¥æ˜¯å¦æœ‰ "Unknown" ä½¿ç”¨è€…ï¼ˆé€šå¸¸æ˜¯ç¤¾ç¾¤ç‰¹å¾µï¼‰
    has_unknown_user = any(user == 'Unknown' for user in user_names)
    
    # æª¢æŸ¥ä½¿ç”¨è€…åç¨±çš„å¤šæ¨£æ€§
    user_name_patterns = []
    for user in user_names:
        if '_' in user:
            user_name_patterns.append('underscore')
        if any(char.isdigit() for char in user):
            user_name_patterns.append('has_number')
        if len(user.split()) > 1:
            user_name_patterns.append('multi_word')
    
    has_diverse_patterns = len(set(user_name_patterns)) > 1
    
    # åˆ¤æ–·é‚è¼¯ï¼ˆæ›´åš´æ ¼çš„ç¤¾ç¾¤æª¢æ¸¬ï¼‰
    group_indicators = 0
    
    if unique_users > 3:  # é™ä½é–¾å€¼
        group_indicators += 1
    if has_system_msgs:
        group_indicators += 2  # ç³»çµ±è¨Šæ¯æ˜¯å¼·çƒˆæŒ‡æ¨™
    if has_complex_names:
        group_indicators += 1
    if has_unknown_user:
        group_indicators += 1
    if has_diverse_patterns:
        group_indicators += 1
    
    # å¦‚æœæœ‰å¤šå€‹æŒ‡æ¨™æŒ‡å‘ç¤¾ç¾¤ï¼Œå‰‡åˆ¤å®šç‚ºç¤¾ç¾¤
    if group_indicators >= 2:
        return 'group'
    else:
        return 'private'

def smart_identify_users(file_path: str, sample_count: int, config: Dict) -> Tuple[List[str], Dict[str, str]]:
    """
    æ™ºèƒ½è­˜åˆ¥èŠå¤©è¨˜éŒ„ä¸­çš„ä½¿ç”¨è€…åç¨±
    
    Args:
        file_path: èŠå¤©è¨˜éŒ„æª”æ¡ˆè·¯å¾‘
        sample_count: åˆ†ææ¨£æœ¬æ•¸é‡
        config: é…ç½®å­—å…¸ï¼ŒåŒ…å«åˆ†æè¨­å®š
        
    Returns:
        (çœŸæ­£ä½¿ç”¨è€…åˆ—è¡¨, ä½¿ç”¨è€…åç¨±æ˜ å°„å­—å…¸)
    """
    print(f"æ­£åœ¨åˆ†ææª”æ¡ˆï¼š{os.path.basename(file_path)}")
    print(f"æå–å‰ {sample_count} æ¢è¨Šæ¯é€²è¡Œåˆ†æ...")
    
    # æå–è¨Šæ¯æ¨£æœ¬
    samples = extract_message_samples(file_path, sample_count)
    
    if not samples:
        print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„è¨Šæ¯æ¨£æœ¬")
        return [], {}
    
    print(f"æˆåŠŸæå– {len(samples)} æ¢è¨Šæ¯æ¨£æœ¬")
    
    # æª¢æ¸¬èŠå¤©æ ¼å¼
    chat_format = detect_chat_format(samples)
    print(f"æª¢æ¸¬åˆ°èŠå¤©æ ¼å¼ï¼š{'ç¤¾ç¾¤' if chat_format == 'group' else 'ç§èŠ'}")
    
    # åˆ†æä½¿ç”¨è€…æ¨¡å¼
    analysis = analyze_user_patterns(samples)
    
    print(f"ç™¼ç¾ {len(analysis)} å€‹ä¸åŒçš„ä½¿ç”¨è€…åç¨±")
    
    # å¾é…ç½®ä¸­ç²å–é »ç‡åƒæ•¸
    min_frequency_private = config['analysis_settings']['min_frequency_private_ç§èŠæœ€å°é »ç‡']
    min_frequency_group = config['analysis_settings']['min_frequency_group_ç¤¾ç¾¤æœ€å°é »ç‡']
    
    # æ ¹æ“šæ ¼å¼èª¿æ•´è­˜åˆ¥åƒæ•¸
    if chat_format == 'group':
        min_frequency = min_frequency_group  # ç¤¾ç¾¤ç’°å¢ƒé™ä½é »ç‡è¦æ±‚
        print("ä½¿ç”¨ç¤¾ç¾¤æ¨¡å¼è­˜åˆ¥ï¼ˆé™ä½é »ç‡è¦æ±‚ï¼‰")
    else:
        min_frequency = min_frequency_private  # ç§èŠç’°å¢ƒä¿æŒè¼ƒé«˜è¦æ±‚
        print("ä½¿ç”¨ç§èŠæ¨¡å¼è­˜åˆ¥")
    
    # è­˜åˆ¥çœŸæ­£ä½¿ç”¨è€…
    real_users = identify_real_users(analysis, min_frequency, config)
    
    print(f"è­˜åˆ¥å‡º {len(real_users)} å€‹çœŸæ­£ä½¿ç”¨è€…ï¼š")
    for i, user in enumerate(real_users, 1):
        stats = analysis[user]
        print(f"  {i}. {user} (å‡ºç¾ {stats['count']} æ¬¡ï¼Œé »ç‡ {stats['frequency']:.2%})")
    
    # å‰µå»ºæ˜ å°„
    mapping = create_user_mapping(real_users, analysis)
    
    if mapping:
        print(f"å‰µå»ºäº† {len(mapping)} å€‹ä½¿ç”¨è€…åç¨±æ˜ å°„")
    
    return real_users, mapping

if __name__ == "__main__":
    # æ¸¬è©¦åŠŸèƒ½
    test_file = "data/raw/[LINE]è–ä¼¯ç´_Peggy æ—ä½©è±.txt"
    if os.path.exists(test_file):
        real_users, mapping = smart_identify_users(test_file)
        print(f"\næ¸¬è©¦çµæœï¼š")
        print(f"çœŸæ­£ä½¿ç”¨è€…ï¼š{real_users}")
        print(f"æ˜ å°„é—œä¿‚ï¼š{mapping}")
    else:
        print(f"æ¸¬è©¦æª”æ¡ˆä¸å­˜åœ¨ï¼š{test_file}") 